{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C-LIENet_Test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kVuxjB0wfKjZ"},"source":["import numpy as np \n","%tensorflow_version 1.x\n","import os\n","from keras.preprocessing.image import ImageDataGenerator\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n","import tensorflow as tf\n","from __future__ import print_function\n","\n","from keras import *\n","from keras import backend as K\n","from keras.callbacks import *\n","from keras.layers import *\n","from keras.models import *\n","from keras.optimizers import *\n","from keras.preprocessing.image import *\n","from keras.losses import *\n","from keras import backend as K\n","from tensorflow.python.compat import *\n","from tensorflow.python.framework import *\n","from tensorflow.python.ops import *\n","from tensorflow.python.util import *\n","from tensorflow.python.util.tf_export import *\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import cv2\n","from __future__ import absolute_import, division, print_function\n","from scipy import signal\n","from math import log2, log10\n","from scipy.ndimage import generic_laplace,uniform_filter,correlate,gaussian_filter\n","from scipy.ndimage.filters import uniform_filter,gaussian_filter\n","from scipy import signal\n","import warnings\n","from enum import Enum\n","from PIL import Image\n","import time\n","import math\n","%matplotlib inline\n","tf.logging.set_verbosity(tf.logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mk3cHwPuVbrI"},"source":["## PATHS AND EXPERIMENT INFO ##\r\n","test_data_image_folder = 'data/LID/test/low'\r\n","test_data_mask_folder = 'data/LID/test/high'\r\n","model_folder = 'clienet/models'\r\n","model_name = 'model_clienet.h5'\r\n","save_path = 'clienet/predictions'\r\n","\r\n","IMG_HEIGHT = 256\r\n","IMG_WIDTH = 256\r\n","\r\n","if not os.path.exists(save_path):\r\n","    os.makedirs(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deEC2zoZeIus"},"source":["## METRICS DEFINITIONS ##\n","\n","def euclidean_distance_loss_nosqrt(y_true, y_pred):\n","  return tf.reduce_sum(tf.square(y_pred - y_true))\n","\n","class Filter(Enum):\n","\tUNIFORM = 0\n","\tGAUSSIAN = 1\n","\n","def _get_sums(GT,P,win,mode='same'):\n","\tmu1,mu2 = (filter2(GT,win,mode),filter2(P,win,mode))\n","\treturn mu1*mu1, mu2*mu2, mu1*mu2\n","\n","def _get_sigmas(GT,P,win,mode='same',**kwargs):\n","\tif 'sums' in kwargs:\n","\t\tGT_sum_sq,P_sum_sq,GT_P_sum_mul = kwargs['sums']\n","\telse:\n","\t\tGT_sum_sq,P_sum_sq,GT_P_sum_mul = _get_sums(GT,P,win,mode)\n","\n","\treturn filter2(GT*GT,win,mode)  - GT_sum_sq,\\\n","\t\t\tfilter2(P*P,win,mode)  - P_sum_sq, \\\n","\t\t\tfilter2(GT*P,win,mode) - GT_P_sum_mul\n","\n","def fspecial(fltr,ws,**kwargs):\n","\tif fltr == Filter.UNIFORM:\n","\t\treturn np.ones((ws,ws))/ ws**2\n","\telif fltr == Filter.GAUSSIAN:\n","\t\tx, y = np.mgrid[-ws//2 + 1:ws//2 + 1, -ws//2 + 1:ws//2 + 1]\n","\t\tg = np.exp(-((x**2 + y**2)/(2.0*kwargs['sigma']**2)))\n","\t\tg[ g < np.finfo(g.dtype).eps*g.max() ] = 0\n","\t\tassert g.shape == (ws,ws)\n","\t\tden = g.sum()\n","\t\tif den !=0:\n","\t\t\tg/=den\n","\t\treturn g\n","\treturn None\n","\n","def filter2(img,fltr,mode='same'):\n","\treturn signal.convolve2d(img, np.rot90(fltr,2), mode=mode)\n","\n","def _vifp_single(GT,P,sigma_nsq):\n","\tEPS = 1e-10\n","\tnum =0.0\n","\tden =0.0\n","\tfor scale in range(1,5):\n","\t\tN=2.0**(4-scale+1)+1\n","\t\twin = fspecial(Filter.GAUSSIAN,ws=N,sigma=N/5)\n","\n","\t\tif scale >1:\n","\t\t\tGT = filter2(GT,win,'valid')[::2, ::2]\n","\t\t\tP = filter2(P,win,'valid')[::2, ::2]\n","\n","\t\tGT_sum_sq,P_sum_sq,GT_P_sum_mul = _get_sums(GT,P,win,mode='valid')\n","\t\tsigmaGT_sq,sigmaP_sq,sigmaGT_P = _get_sigmas(GT,P,win,mode='valid',sums=(GT_sum_sq,P_sum_sq,GT_P_sum_mul))\n","\n","\n","\t\tsigmaGT_sq[sigmaGT_sq<0]=0\n","\t\tsigmaP_sq[sigmaP_sq<0]=0\n","\n","\t\tg=sigmaGT_P /(sigmaGT_sq+EPS)\n","\t\tsv_sq=sigmaP_sq-g*sigmaGT_P\n","\t\t\n","\t\tg[sigmaGT_sq<EPS]=0\n","\t\tsv_sq[sigmaGT_sq<EPS]=sigmaP_sq[sigmaGT_sq<EPS]\n","\t\tsigmaGT_sq[sigmaGT_sq<EPS]=0\n","\t\t\n","\t\tg[sigmaP_sq<EPS]=0\n","\t\tsv_sq[sigmaP_sq<EPS]=0\n","\t\t\n","\t\tsv_sq[g<0]=sigmaP_sq[g<0]\n","\t\tg[g<0]=0\n","\t\tsv_sq[sv_sq<=EPS]=EPS\n","\t\t\n","\t\n","\t\tnum += np.sum(np.log10(1.0+(g**2.)*sigmaGT_sq/(sv_sq+sigma_nsq)))\n","\t\tden += np.sum(np.log10(1.0+sigmaGT_sq/sigma_nsq))\n","\n","\treturn num/den\n","\n","# VISUAL INDEX FIDELITY\n","def vifp(GT,P,sigma_nsq=2):\n","\treturn np.mean([_vifp_single(GT[:,:,i],P[:,:,i],sigma_nsq) for i in range(GT.shape[2])])\n","\n","# PEAK SIGNAL TO NOISE RATIO\n","def psnr(y_true, y_pred):\n","    return tf.image.psnr(y_true, y_pred, max_val=255.0)\n","\n","# ABSOLUTE BRIGHTNESS\n","def ab(y_true, y_pred):\n","    return np.abs(np.mean(y_true[:,:,:3])-np.mean(y_pred[:,:,:3]))\n","\n","# STRUCTURAL SIMILARITY INDEX\n","def ssim(y_true, y_pred):\n","    return tf.image.ssim(y_true, y_pred, max_val=255.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYLUgMXaVIBJ"},"source":["## LOAD TEST IMAGES AND MASK ##\r\n","test_images = []\r\n","test_masks = []\r\n","\r\n","test_files = os.listdir(test_data_image_folder)\r\n","test_files = sorted([file for file in test_files if file.endswith(\".jpg\")])\r\n","\r\n","print(test_files)\r\n","\r\n","for image in test_files:\r\n","\r\n","  test_img = cv2.imread(os.path.join(test_data_image_folder, image))\r\n","  test_img = cv2.resize(test_img, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_CUBIC)\r\n","  test_images.append(test_img)\r\n","\r\n","  test_mask = cv2.imread(os.path.join(test_data_mask_folder, image))\r\n","  test_mask = cv2.resize(test_mask, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_CUBIC)\r\n","  test_masks.append(test_mask)\r\n","\r\n","test_image_array = np.array(test_images)\r\n","test_mask_array = np.array(test_masks)\r\n","\r\n","print('TEST IMAGE SHAPE:',test_image_array.shape,' TEST MASK SHAPE:',test_mask_array.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sueZ9ma_EG70"},"source":["## DEFINE MODEL BLOCKS ##\n","\n","def _define_conv_block(\n","    input_, layers, filters,\n","    kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal', **kwargs):\n","    output_ = Conv2D(filters, kernel_size, activation = activation, padding = padding, kernel_initializer = kernel_initializer, **kwargs)(input_)\n","    for layer in range(1, layers):\n","        output_ = Conv2D(filters, kernel_size, activation = activation, padding = padding, kernel_initializer = kernel_initializer, **kwargs)(output_)\n","    return output_\n","\n","def _define_sep_conv_block(\n","    input_, layers, filters,\n","    kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal', **kwargs):\n","    output_ = SeparableConv2D(filters, kernel_size, activation = activation, padding = padding, kernel_initializer = kernel_initializer, **kwargs)(input_)\n","    for layer in range(1, layers):\n","        output_ = SeparableConv2D(filters, kernel_size, activation = activation, padding = padding, kernel_initializer = kernel_initializer, **kwargs)(output_)\n","    return output_\n","\n","def _define_aspp_block(input_, filters, dilation_rates=list((1, 3, 5, 7)),\n","                       kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal', **kwargs):\n","    num_parallel_outputs = len(dilation_rates)\n","    parallel_outputs = [None] * num_parallel_outputs\n","    for output_idx in range(num_parallel_outputs):\n","        dilation_rate = (dilation_rates[output_idx], dilation_rates[output_idx])\n","        parallel_outputs[output_idx] = SeparableConv2D(filters, kernel_size, dilation_rate = dilation_rate, activation = activation, padding = padding, kernel_initializer = kernel_initializer, **kwargs)(input_)\n","    output_ = concatenate(parallel_outputs, axis=3)\n","    return output_\n","\n","def encoder_decoder_with_aspp_blocks(input_shape = (256, 256, 3)):\n","    inputs = Input(input_shape)\n","    \n","    block1 = _define_conv_block(inputs, 2, 64)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(block1)\n","\n","    block2 = _define_aspp_block(pool1, 64)\n","    block2 = _define_sep_conv_block(block2, 2, 64)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(block2)\n","    \n","    block3 = _define_aspp_block(pool2, 128)\n","    block3 = _define_sep_conv_block(block3, 2, 128)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(block3)\n","    \n","    block4 = _define_aspp_block(pool3, 256)\n","    block4 = _define_sep_conv_block(block4, 2, 256)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(block4)\n","\n","    block5 = _define_aspp_block(pool4, 512)\n","    block5 = _define_sep_conv_block(block5, 4, 512)\n","    \n","    up6 = SeparableConv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(block5))\n","    # block4 = _define_sep_conv_block(block4, 2, 512)\n","    merge6 = concatenate([block4, up6], axis = 3)\n","    block6 = _define_sep_conv_block(merge6, 2, 512)\n","\n","    up7 = SeparableConv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(block6))\n","    # block3 = _define_sep_conv_block(block3, 2, 256)\n","    merge7 = concatenate([block3, up7], axis = 3)\n","    block7 = _define_sep_conv_block(merge7, 2, 256)\n","\n","    up8 = SeparableConv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(block7))\n","    # block2 = _define_sep_conv_block(block2, 2, 128)\n","    merge8 = concatenate([block2, up8], axis = 3)\n","    block8 = _define_sep_conv_block(merge8, 2, 128)\n","\n","    up9 = SeparableConv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(block8))\n","    # block1 = _define_sep_conv_block(block1, 2, 64)\n","    merge9 = concatenate([block1, up9], axis = 3)    \n","    # block9 = _define_sep_conv_block(merge9, 2, 64)\n","      \n","    block9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    output = Conv2D(3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(block9)\n","    model = Model(inputs = inputs, outputs = output)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"inewcHfi8UUI"},"source":["## CONFIGURE DEFINE MODEL ##\n","\n","# Model loss and metrics\n","loss = 'mse'\n","metrics = ['accuracy']\n","\n","# Configure Optimizer\n","learning_rate = 1e-4\n","optimizer = Adam(lr = learning_rate)\n","\n","# Build Model\n","model = encoder_decoder_with_aspp_blocks()\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","# model.summary()\n","\n","# Load Weights\n","model.load_weights(model_folder + '/' + model_name)\n","\n","## PREDICT OUTPUTS ##\n","predictions = model.predict(test_image_array)\n","print(predictions.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaUahlXtpslN"},"source":["## CALCULATE METRICS ##\r\n","\r\n","sum_vif_org = 0\r\n","sum_ab_org = 0\r\n","sum_vif_pred = 0\r\n","sum_ab_pred = 0\r\n","\r\n","num  = predictions.shape[0]\r\n","\r\n","for i in range(test_image_array.shape[0]):\r\n","  # print(str(i))      \\\\ uncomment to track progress\r\n","\r\n","  ## UNCOMMENT THESE TWO LINES TO STORE PREDICTIONS AND RESPECTIVE INPUTS##\r\n","  ####\r\n","  # cv2.imwrite(save_path + '/' + str(i) + '_output.jpg', prediction[i])\r\n","  # cv2.imwrite(save_path + '/' + str(i) + '_input.jpg', test_image_array[i])\r\n","  ####\r\n","\r\n","  vif_org = vifp(test_mask_array[i],test_image_array[i])\r\n","  ab_org = ab(test_mask_array[i],test_image_array[i])\r\n","  vif_pred = vifp(test_mask_array[i],predictions[i]) \r\n","  ab_pred = ab(test_mask_array[i],predictions[i]) \r\n","\r\n","  sum_vif_org = sum_vif_org + vif_org\r\n","  sum_ab_org = sum_ab_org + ab_org\r\n","  sum_vif_pred = sum_vif_pred + vif_pred\r\n","  sum_ab_pred = sum_ab_pred + ab_pred\r\n","\r\n","vif_org_avg = sum_vif_org / num\r\n","ab_org_avg = sum_ab_org / num\r\n","vif_pred_avg = sum_vif_pred / num\r\n","ab_pred_avg = sum_ab_pred / num\r\n","\r\n","test_image_array_t = tf.convert_to_tensor(test_image_array[:50],dtype=tf.float32)\r\n","predictions_t = tf.convert_to_tensor(predictions,dtype=tf.float32)\r\n","test_mask_array_t = tf.convert_to_tensor(test_mask_array[:50],dtype=tf.float32)\r\n","\r\n","with tf.Session() as sess:psnr_avg_org = tf.math.reduce_mean(psnr(test_mask_array_t, test_image_array_t)).eval()\r\n","with tf.Session() as sess:psnr_avg_pred = tf.math.reduce_mean(psnr(test_mask_array_t, predictions_t)).eval()\r\n","with tf.Session() as sess:ssim_avg_org = tf.math.reduce_mean(ssim(test_mask_array_t, test_image_array_t)).eval()\r\n","with tf.Session() as sess:ssim_avg_pred = tf.math.reduce_mean(ssim(test_mask_array_t, predictions_t)).eval()\r\n","\r\n","print('psnr org:'+ str(psnr_avg_org))\r\n","print('psnr pred:'+ str(psnr_avg_pred))\r\n","print('ssim org t:'+ str(ssim_avg_org))\r\n","print('ssim pred t:'+ str(ssim_avg_pred))\r\n","print('vif org:'+ str(vif_org_avg))\r\n","print('vif pred:'+ str(vif_pred_avg))\r\n","print('ab org:'+ str(ab_org_avg))\r\n","print('ab pred:'+ str(ab_pred_avg))\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBVVrNZAHpwO"},"source":["from google.colab.patches import cv2_imshow\r\n","\r\n","# first row: input image\r\n","# second row: output mask\r\n","# third row: output prediction\r\n","\r\n","for i in range(test_image_array.shape[0]):\r\n","  cv2_imshow(test_image_array[i])\r\n","  cv2_imshow(test_mask_array[i])\r\n","  cv2_imshow(predictions[i])\r\n","\r\n"],"execution_count":null,"outputs":[]}]}